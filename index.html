<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="nktRfYLkKb-FJ68vQEr75vcq7lXEPi_6hHDnl2eg_9s"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Yongtao Ge | è‘›æ¶Œæ¶›</title> <meta name="author" content="Yongtao Ge"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@500&family=Lato&display=swap" rel="stylesheet"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/favicon.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://yongtaoge.github.io/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <span class="contact-icon text-center" style="line-height: 1em;"> <a href="mailto:yongtao.ge@adelaide.edu.au"><i class="fa fa-envelope-square gm-icon"></i></a> <a href="https://scholar.google.com/citations?userid=r8SywYYAAAAJ&amp;user=r8SywYYAAAAJ" target="_blank" title="Google Scholar" rel="noopener noreferrer"><i class="ai ai-google-scholar-square gs-icon"></i></a> <a href="https://www.github.com/YongtaoGe" target="_blank" title="GitHub" rel="noopener noreferrer"><i class="fab fa-github-square gh-icon"></i></a> <a href="https://twitter.com/ovoz_z" target="_blank" title="Twitter" rel="noopener noreferrer"><i class="fab fa-twitter-square tw-icon"></i></a> <a href="https://www.linkedin.com/in/YongtaoGe" target="_blank" title="LinkedIn" rel="noopener noreferrer"><i class="fab fa-linkedin li-icon"></i></a> </span> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Yongtao Ge | è‘›æ¶Œæ¶› </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> </div> <div class="clearfix"> <p>I am a Ph.D candidate in Computer Science, working in <a href="https://www.adelaide.edu.au/aiml/" target="_blank" rel="noopener noreferrer">AIML</a>, the University of Adelaide, with <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Prof. Chunhua Shen</a>. Before that, I received the M. Eng degree from Southeast University and B. Eng degree from Nanjing University of Science and Technology.</p> <p>My research interest mainly lies in the intersection of computer vision and computer graphics, including 3D scene reconstruction, 2D/3D human pose estimation, and vision-centric multi-modality foundation models.</p> <font color="red"> I will graduate in the late 2024 and I am looking for industry positions or Post-doc opportunities. Please feel free to reach out (yongtao.ge@adelaide.edu.au) if you have openings and find me might be a fit. </font> <p><br></p> </div> <div class="news"> <h2>News</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jun 19, 2024</th> <td> Release <a href="https://github.com/aim-uofa/GeoBench" target="_blank" rel="noopener noreferrer">GeoBench</a>, a Monocular Geometry Benchmark for evaluating SOTA geometry estimation foundation models. ðŸŽ‰ </td> </tr> <tr> <th scope="row">Mar 29, 2024</th> <td> Release HumanWild, feel free to try our <a href="https://huggingface.co/spaces/geyongtao/HumanWild" target="_blank" rel="noopener noreferrer">Huggingface Demo</a>. ðŸŽ‰ </td> </tr> <tr> <th scope="row">Jul 18, 2023</th> <td> Zolly is accepted by ICCV 2023, selected as oral (top 1.8%). <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Mar 27, 2023</th> <td> Release Zolly, focusing on perspective-distorted 3D human pose and shape estimation. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Nov 19, 2022</th> <td> One paper is accepted by AAAI 2023. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> </table> </div> </div> <div class="publications"> <h2>Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/geobench_logo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/geobench_logo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/geobench_logo-1400.webp"></source> <img src="/assets/img/publication_preview/geobench_logo.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="geobench_logo.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ge2024geobench" class="col-sm-8"> <div class="title">GeoBench: Benchmarking and Analyzing Monocular Geometry Estimation Models</div> <div class="author"> <em>Yongtao Ge</em>,Â Guangkai Xu,Â Zhiyue Zhao,Â Zheng Huang,Â Libo Sun,Â Yanlong Sun,Â Hao Chen,Â andÂ <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2406.12671</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/aim-uofa/GeoBench" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ge2024geobench</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GeoBench: Benchmarking and Analyzing Monocular Geometry Estimation Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ge, Yongtao and Xu, Guangkai and Zhao, Zhiyue and Huang, Zheng and Sun, Libo and Sun, Yanlong and Chen, Hao and Shen, Chunhua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2406.12671}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{arXiv.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/humanwild.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/humanwild.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/humanwild.gif-1400.webp"></source> <img src="/assets/img/publication_preview/humanwild.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="humanwild.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ge2024humanwild" class="col-sm-8"> <div class="title">3D Human Reconstruction in the Wild with Synthetic Data Using Generative Models</div> <div class="author"> <em>Yongtao Ge</em>,Â <a href="https://wenjiawang0312.github.io/" target="_blank" rel="noopener noreferrer">Wenjia Wang</a>,Â Yongfan Chen,Â Hao Chen,Â andÂ <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a> </div> <div class="periodical"> <em>In arXiv.org</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2403.11111" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://yongtaoge.github.io/projects/humanwild/" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ge2024humanwild</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{3D Human Reconstruction in the Wild with Synthetic Data Using Generative Models}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{arXiv.org}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ge, Yongtao and Wang, Wenjia and Chen, Yongfan and Chen, Hao and Shen, Chunhua}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/genpercept_pipeline-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/genpercept_pipeline-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/genpercept_pipeline-1400.webp"></source> <img src="/assets/img/publication_preview/genpercept_pipeline.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="genpercept_pipeline.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2024genpercept" class="col-sm-8"> <div class="title">Diffusion Models Trained with Large Data Are Transferable Visual Models</div> <div class="author"> Guangkai Xu,Â <em>Yongtao Ge</em>,Â Mingyu Liu,Â Chengxiang Fan,Â Kangyang Xie,Â Zhiyue Zhao,Â Hao Chen,Â andÂ <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a> </div> <div class="periodical"> <em>In arXiv.org</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2403.06090" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xu2024genpercept</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusion Models Trained with Large Data Are Transferable Visual Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Guangkai and Ge, Yongtao and Liu, Mingyu and Fan, Chengxiang and Xie, Kangyang and Zhao, Zhiyue and Chen, Hao and Shen, Chunhua}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{arXiv.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/zolly-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/zolly-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/zolly-1400.webp"></source> <img src="/assets/img/publication_preview/zolly.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="zolly.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2023zolly" class="col-sm-8"> <div class="title">Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction</div> <div class="author"> <a href="https://wenjiawang0312.github.io/" target="_blank" rel="noopener noreferrer">Wenjia Wang</a>,Â <em>Yongtao Ge</em>,Â Haiyi Mei,Â <a href="https://caizhongang.github.io/" target="_blank" rel="noopener noreferrer">Zhongang Cai</a>,Â Qingping Sun,Â Yanjun Wang,Â <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a>,Â <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Lei Yang</a>,Â andÂ <a href="https://www.cs.hku.hk/index.php/people/academic-staff/taku" target="_blank" rel="noopener noreferrer">Komura Taku</a> </div> <div class="periodical"> <em>In Proc. of the IEEE International Conf. on Computer Vision (ICCV Oral)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2303.13796" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/WenjiaWang0312/Zolly" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2023zolly</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. of the IEEE International Conf. on Computer Vision (ICCV Oral)}</span><span class="p">,</span>
  <span class="na">stars</span> <span class="p">=</span> <span class="s">{&lt;a href="https://github.com/WenjiaWang0312/Zolly"&gt;
            &lt;img alt="GitHub Repo stars" style="vertical-align: top" 
            src="https://img.shields.io/github/stars/WenjiaWang0312/Zolly?style=social"&gt;
          &lt;/a&gt;}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Wenjia and Ge, Yongtao and Mei, Haiyi and Cai, Zhongang and Sun, Qingping and Wang, Yanjun and Shen, Chunhua and Yang, Lei and Taku, Komura}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/poseur_arch-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/poseur_arch-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/poseur_arch-1400.webp"></source> <img src="/assets/img/publication_preview/poseur_arch.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="poseur_arch.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mao2022poseur" class="col-sm-8"> <div class="title">Poseur: Direct Human Pose Regression with Transformers</div> <div class="author"> <a href="https://scholar.google.com/citations?hl=no&amp;user=Qu-QXTsAAAAJ" target="_blank" rel="noopener noreferrer">Weian Mao*</a>,Â <em>Yongtao Ge*</em>,Â <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a>,Â <a href="https://zhitian.xyz/" target="_blank" rel="noopener noreferrer">Zhi Tian</a>,Â <a href="https://www.xloong.wang/" target="_blank" rel="noopener noreferrer">Xinlong Wang</a>,Â <a href="https://scholar.google.com/citations?user=YHzKee8AAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer">Zhibin Wang</a>,Â andÂ <a href="https://cs.adelaide.edu.au/~hengel/" target="_blank" rel="noopener noreferrer">Anton van den Hengel</a> </div> <div class="periodical"> <em>In Proc. of the European Conf. on Computer Vision (ECCV)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136660071.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136660071-supp.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a> <a href="https://github.com/aim-uofa/Poseur" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mao2022poseur</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Poseur: Direct Human Pose Regression with Transformers}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. of the European Conf. on Computer Vision (ECCV)}</span><span class="p">,</span>
  <span class="na">stars</span> <span class="p">=</span> <span class="s">{
        &lt;a href="https://github.com/aim-uofa/Poseur"&gt;
          &lt;img alt="GitHub Repo stars" 
            style="vertical-align: top"
            src="https://img.shields.io/github/stars/aim-uofa/Poseur?style=social"&gt;
        &lt;/a&gt;}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mao*, Weian and Ge*, Yongtao and Shen, Chunhua and Tian, Zhi and Wang, Xinlong and Wang, Zhibin and Hengel, Anton van den}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/point_teaching_arch-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/point_teaching_arch-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/point_teaching_arch-1400.webp"></source> <img src="/assets/img/publication_preview/point_teaching_arch.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="point_teaching_arch.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ge2023point" class="col-sm-8"> <div class="title">Point-Teaching: Weakly Semi-Supervised Object Detection with Point Annotations</div> <div class="author"> <em>Yongtao Ge*</em>,Â <a href="https://scholar.google.com/citations?user=97a5a_oAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer">Qiang Zhou*</a>,Â <a href="https://www.xloong.wang/" target="_blank" rel="noopener noreferrer">Xinlong Wang</a>,Â <a href="https://cshen.github.io/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a>,Â <a href="https://scholar.google.com/citations?user=YHzKee8AAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer">Zhibin Wang</a>,Â andÂ <a href="https://scholar.google.com/citations?user=pHN-QIwAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer">Hao Li</a> </div> <div class="periodical"> <em>In AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2206.00274" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/YongtaoGe/Point-Teaching" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ge2023point</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Point-Teaching: Weakly Semi-Supervised Object Detection with Point Annotations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ge*, Yongtao and Zhou*, Qiang and Wang, Xinlong and Shen, Chunhua and Wang, Zhibin and Li, Hao}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence (AAAI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2024 Yongtao Ge. <script type="text/javascript" src="//rf.revolvermaps.com/0/0/3.js?i=5vy2m676rx4&amp;b=0&amp;s=22&amp;m=2&amp;cl=ffffff&amp;co=010020&amp;cd=aa0000&amp;v0=60&amp;v1=60&amp;r=1" async="async"></script> Last updated: June 21, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-V036EPBJ99"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-V036EPBJ99");</script> <script async src="https://cdn.panelbear.com/analytics.js?site=6ZQ5fbjk8uu"></script> <script>window.panelbear=window.panelbear||function(){(window.panelbear.q=window.panelbear.q||[]).push(arguments)},panelbear("config",{site:"6ZQ5fbjk8uu"});</script> <script>var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.getElementById("WeChatBtn");wechatBtn.onclick=function(){wechatModal.style.display="block"},window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> </body> </html>